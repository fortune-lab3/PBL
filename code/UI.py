import os, time, re, base64
import streamlit as st
from huggingface_hub import InferenceClient
from httpx import ConnectTimeout, ReadTimeout, HTTPError
from docx import Document
import io

# ------------------------------------------------
# Hugging Face è¨­å®š
# ------------------------------------------------
HF_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN", "")
MODEL_ID = "Qwen/Qwen3-4B-Instruct-2507"

# =========================
# å‰å‡¦ç†
# =========================
def remove_strings(text: str) -> str:
    pattern = re.compile(r'ã€.*?ã€‘|[ï¼²R][ãƒ¼-]\d+|\n|\t|\s+|â– |ï¼Š')
    return pattern.sub('', text or "")

def normalize_output(text: str) -> str:
    text = (text or "").strip()
    text = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL)
    text = re.sub(r"[a-zA-Z]+", "", text)
    return text.replace("\n", "").replace("\r", "").strip()

def count_chars(text: str) -> int:
    return len((text or "").replace("\n", "").replace("\r", ""))

# =========================
# æ–‡åˆ†å‰²
# =========================
def split_sentences(text: str) -> list[str]:
    text = normalize_output(text)
    parts = re.split(r"(ã€‚)", text)
    sentences = []
    for i in range(0, len(parts) - 1, 2):
        sentences.append(parts[i] + "ã€‚")
    return sentences

# =========================
# HF å¿œç­”æŠ½å‡º & å‘¼ã³å‡ºã—
# =========================
def _extract_message_text(choice) -> str:
    msg = getattr(choice, "message", None)
    if isinstance(msg, dict):
        return msg.get("content", "")
    return getattr(msg, "content", "")

def _call_chat(client, messages, max_tokens, temperature):
    for attempt in range(3):
        try:
            resp = client.chat.completions.create(
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
            )
            return _extract_message_text(resp.choices[0]).strip()

        except (ConnectTimeout, ReadTimeout):
            time.sleep(2 ** attempt)
        except HTTPError as e:
            if getattr(e.response, "status_code", 500) >= 500:
                time.sleep(2 ** attempt)
            else:
                raise
    return ""

# =========================
# å¾ŒåŠã ã‘å†èª¿æ•´
# =========================
def adjust_tail_with_llm(
    client,
    head_sentences: list[str],
    tail_sentence: str,
    target_chars: int,
    temperature: float,
) -> str:
    head = "".join(head_sentences)

    prompt = (
        f"æ¬¡ã®æ–°èåºƒå‘Šæ–‡ã®ã€å¾ŒåŠã€‘ã ã‘ã‚’ã€æ„å‘³ã‚’å¤‰ãˆãšã«è‡ªç„¶ã«æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\n"
        f"ã€æ¡ä»¶ã€‘\n"
        f"ãƒ»å‰åŠã¯å¤‰æ›´ã—ãªã„\n"
        f"ãƒ»å…¨ä½“ãŒã ã„ãŸã„ {target_chars} æ–‡å­—å‰å¾Œã«ãªã‚‹ã‚ˆã†èª¿æ•´\n"
        f"ãƒ»æ”¹è¡Œãªã—ä¸€æ®µè½\n"
        f"ãƒ»å›ºæœ‰åè©ã‚’ä½¿ã‚ãªã„\n"
        f"ãƒ»èª‡å¤§è¡¨ç¾ã‚’é¿ã‘ã‚‹\n"
        f"ãƒ»æ–‡æœ«ã¯å¿…ãšã€Œã€‚ã€ã§çµ‚ãˆã‚‹\n\n"
        f"ã€å‰åŠã€‘\n{head}\n\n"
        f"ã€å¾ŒåŠï¼ˆä¿®æ­£å¯¾è±¡ï¼‰ã€‘\n{tail_sentence}\n\n"
        f"ã€ä¿®æ­£å¾Œã®å¾ŒåŠã€‘"
    )

    new_tail = _call_chat(
        client,
        [{"role": "user", "content": prompt}],
        max_tokens=200,
        temperature=temperature,
    )

    return head + normalize_output(new_tail)

# =========================
# åºƒå‘Šæ–‡ç”Ÿæˆï¼ˆç²¾åº¦å„ªå…ˆï¼‰
# =========================
def generate_newspaper_ad_api(text: str, target_chars: int, temperature: float = 0.2) -> str:
    if not HF_TOKEN:
        raise RuntimeError("HUGGINGFACEHUB_API_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    client = InferenceClient(model=MODEL_ID, token=HF_TOKEN, timeout=60.0)

    cleaned = remove_strings(text)
    max_tokens = int(target_chars * 3)

    # â‘  ã¾ãšè‡ªç„¶ã•æœ€å„ªå…ˆã§ç”Ÿæˆ
    ad = _call_chat(
        client,
        [{"role": "user", "content": (
            f"æ¬¡ã®åŸç¨¿å†…å®¹ã‚’ã‚‚ã¨ã«ã€æ–°èã«æ²è¼‰ã§ãã‚‹åºƒå‘Šæ–‡ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n"
            f"ãƒ»æ—¥æœ¬èªã®ã¿\n"
            f"ãƒ»å›ºæœ‰åè©ã‚’ä½¿ã‚ãªã„\n"
            f"ãƒ»æ”¹è¡Œãªã—ä¸€æ®µè½\n"
            f"ãƒ»æ–‡æœ«ã¯å¿…ãšã€Œã€‚ã€\n"
            f"ãƒ»æ–‡å­—æ•°ã¯ãŠã‚ˆã {target_chars} æ–‡å­—å‰å¾Œ\n"
            f"ãƒ»ç„¡ç†ãªæ–‡å­—æ•°åˆã‚ã›ã¯ã—ãªã„\n\n"
            f"ã€åŸç¨¿ã€‘\n{cleaned}\n\nã€åºƒå‘Šæ–‡ã€‘"
        )}],
        max_tokens=max_tokens,
        temperature=temperature,
    )

    ad = normalize_output(ad)
    sentences = split_sentences(ad)

    # â‘¡ é•·ã™ãã‚‹å ´åˆã®ã¿ã€Œæœ€å¾Œã®1æ–‡ã€ã‚’å†èª¿æ•´
    if len(sentences) >= 2 and len(ad) > target_chars + 10:
        ad = adjust_tail_with_llm(
            client,
            head_sentences=sentences[:-1],
            tail_sentence=sentences[-1],
            target_chars=target_chars,
            temperature=temperature,
        )

    return ad


# keywordæŒ‡å®šã®ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã‚’ãƒªã‚¹ãƒˆåŒ–ã™ã‚‹é–¢æ•°
def build_keyword_instruction(keywords: str):
    if not keywords.strip():
        return ""

    # ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Š â†’ ãƒªã‚¹ãƒˆåŒ–
    words = [w.strip() for w in keywords.split() if w.strip()]

    if not words:
        return ""

    joined = "ã€".join(words)
    return f"ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ï¼š{joined}ã€‚"

# wordãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«
def create_docx_bytes(text: str):
    doc = Document()
    doc.add_paragraph(text)

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer


# =========================
# Streamlit UI
# =========================
def main():
    
    if "current_ad" not in st.session_state:
        st.session_state["current_ad"] = ""

    # å±¥æ­´ä¿æŒ
    if "history" not in st.session_state:
        st.session_state["history"] = []

    st.title("è¦ç´„")
    
    option = st.sidebar.radio("å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ", ("ãƒ†ã‚­ã‚¹ãƒˆ", "ãƒ•ã‚¡ã‚¤ãƒ«"))
    text = ""

    # å…¥åŠ›æ–¹æ³•ï¼šãƒ†ã‚­ã‚¹ãƒˆ
    if option == "ãƒ†ã‚­ã‚¹ãƒˆ":
        text = st.text_area("åºƒå‘Šæ–‡ã«ã—ãŸã„åŸç¨¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=260)

    # å…¥åŠ›æ–¹æ³•ï¼šãƒ•ã‚¡ã‚¤ãƒ«
    else:
        uploadfile = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["txt", "docx"])
        if uploadfile is not None:
            try:
                # ---- TXT ----
                if uploadfile.name.endswith(".txt"):
                    text = uploadfile.read().decode("utf-8", errors="ignore")

                # ---- DOCX ----
                elif uploadfile.name.endswith(".docx"):
                    doc = Document(uploadfile)
                    text = "\n".join([p.text for p in doc.paragraphs])

                # st.success("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                text = ""

    # æ–‡å­—æ•°æŒ‡å®š
    target_chars = st.sidebar.number_input(
        "æ–‡å­—æ•°",
        min_value=10,
        max_value=500,
        value=120,
        step=1
    )
    
    # æ–‡ç« è¡¨ç¾é¸æŠ
    tone = st.sidebar.selectbox(
        "æ–‡ç« ã®ç¡¬ã•ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ["ã‚„ã‚ã‚‰ã‹ã„", "ãµã¤ã†", "ã‹ãŸã„"]
        )
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŒ‡å®š
    keywords = st.sidebar.text_input(
        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŒ‡å®šï¼ˆã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰",
        value=""
        )

    # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«å
    filename = st.sidebar.text_input(
        "ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å",
        value="newspaper"
    )
    ext = st.sidebar.selectbox( "ä¿å­˜å½¢å¼", [".txt", ".docx"] )
    download = filename + ext
    
    # å±¥æ­´    
    st.sidebar.subheader("å±¥æ­´")
    for i, item in enumerate(st.session_state["history"], start=1):
        with st.sidebar.expander(f"å±¥æ­´{i}"):
            st.write(item)

    # =========================
    # è¦ç´„ç”Ÿæˆ
    # =========================
    if st.button("åºƒå‘Šæ–‡ã‚’ç”Ÿæˆ"):
        try:
            if not text.strip():
                st.warning("åŸç¨¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("åºƒå‘Šæ–‡ã‚’ç”Ÿæˆä¸­..."):
                    ad = generate_newspaper_ad_api(text, target_chars)
                    st.session_state["current_ad"] = ad
                    st.session_state["history"].insert(0, ad)
                    st.session_state["history"] = st.session_state["history"][:5]
                
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ï¼ˆåå‰æŒ‡å®šï¼‰
    if st.session_state["current_ad"]:
        st.text_area(
            "ç”Ÿæˆã•ã‚ŒãŸåºƒå‘Šæ–‡",
            st.session_state["current_ad"],
            height=200
            )
        st.markdown(f"æ–‡å­—æ•°ï¼š{len(st.session_state['current_ad'])} æ–‡å­—")
                
        if ext == ".docx":
            file_data = create_docx_bytes(st.session_state["current_ad"])
            mime = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        else:
            file_data = st.session_state["current_ad"]
            mime = "text/plain"
            
        st.download_button(
            label="ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=file_data,
            file_name=download,
            mime=mime
            )

# =========================
# å®Ÿè¡Œ
# =========================
if __name__ == "__main__":
    main()
