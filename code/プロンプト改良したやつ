#åºƒå‘Šæ–‡ç”Ÿæˆã®ã¿

import os, time, re
from huggingface_hub import InferenceClient
from httpx import ConnectTimeout, ReadTimeout, HTTPError

MODEL_ID = "Qwen/Qwen3-4B-Instruct-2507"
HF_TOKEN = os.environ.get("HUGGINGFACEHUB_API_TOKEN", "ã“ã“ã«APIã‚’")

# =========================
# å‰å‡¦ç†ï¼ˆ1æœ¬ç›®ã‹ã‚‰æµç”¨ï¼‰
# =========================
def remove_strings(text: str) -> str:
    pattern = re.compile(r'ã€.*?ã€‘|[ï¼²R][ãƒ¼-]\d+|\n|\t|\s+|â– |ï¼Š')
    return pattern.sub('', text or "")

# =========================
# å‡ºåŠ›æ­£è¦åŒ–ï¼†æ–‡å­—æ•°ã‚«ã‚¦ãƒ³ãƒˆ
# =========================
def normalize_output(text: str) -> str:
    text = (text or "").strip()
    text = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()
    text = re.sub(r"[a-zA-Z]+", "", text).strip()
    text = text.replace("\n", "").replace("\r", "")
    return text

def count_chars(text: str) -> int:
    return len((text or "").replace("\n", "").replace("\r", ""))

# =========================
# HFå¿œç­”æŠ½å‡ºï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³å·®ç•°ã«å¼·ãï¼‰
# =========================
def _extract_message_text(choice) -> str:
    msg = getattr(choice, "message", None)
    if msg is not None and not isinstance(msg, dict):
        content = getattr(msg, "content", None) or getattr(msg, "text", None)
    elif isinstance(msg, dict):
        content = msg.get("content") or msg.get("text")
    else:
        content = None
    return str(content or "").strip()

def _call_chat(client: InferenceClient, messages, max_tokens: int, temperature: float) -> str:
    for attempt in range(3):
        try:
            resp = client.chat.completions.create(
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
            )
            if not getattr(resp, "choices", None):
                return ""
            return _extract_message_text(resp.choices[0])

        except (ConnectTimeout, ReadTimeout):
            print(f"âš ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {attempt+1} å›ç›®ã®ãƒªãƒˆãƒ©ã‚¤ä¸­...")
            time.sleep(2 ** attempt)

        except HTTPError as e:
            status = getattr(getattr(e, "response", None), "status_code", 500)
            if status >= 500:
                print(f"âš ï¸ ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ ({status})ã€ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                time.sleep(2 ** attempt)
            else:
                raise
    return ""

# =========================
# æœ€çµ‚ä¿é™ºï¼šå¥èª­ç‚¹ã§è‡ªç„¶ã«åˆ‡ã‚‹
# =========================
def smart_cut_to_sentence(text: str, target_chars: int, lookback: int = 40) -> str:
    text = normalize_output(text)
    if len(text) <= target_chars:
        return text

    head = text[:target_chars]
    puncts = {"ã€‚", "ï¼", "ï¼Ÿ"}
    start = max(0, target_chars - lookback)

    cut_pos = -1
    for i in range(target_chars - 1, start - 1, -1):
        if head[i] in puncts:
            cut_pos = i + 1
            break

    if cut_pos != -1:
        return head[:cut_pos]

    if target_chars >= 1:
        head = head[:-1] + "ã€‚"
    return head

# =========================
# ä»•ä¸Šã’ï¼šåºƒå‘Šã‚‰ã—ã„å‘¼ã³ã‹ã‘ã‚’æ®‹ã—ã¤ã¤ã€Œå®Œçµã€ã€Œæ–‡æœ«ã€‚ã€ã€Œã¡ã‚‡ã†ã©Næ–‡å­—ã€
# =========================
def finalize_with_llm(
    client: InferenceClient,
    system_prompt: str,
    ad: str,
    target_chars: int,
    max_tokens: int,
    temperature: float,
    rounds: int = 8,
) -> str:
    ad = normalize_output(ad)

    for _ in range(rounds):
        length = count_chars(ad)
        if length == target_chars and ad.endswith("ã€‚"):
            return ad

        prompt = (
            f"æ¬¡ã®æ–‡ç« ã‚’ã€æ„å‘³ã‚’å¤‰ãˆãšã«æ–°èå‘ã‘ã®ç¯€åº¦ã‚ã‚‹åºƒå‘Šæ–‡ã¨ã—ã¦æ•´å½¢ã—ã¦ãã ã•ã„ã€‚\n"
            f"len()ã§æ•°ãˆã¦ã€Œ{target_chars}æ–‡å­—ã¡ã‚‡ã†ã©ã€ã«å¿…ãšåˆã‚ã›ã¾ã™ã€‚\n"
            f"ã€çµ¶å¯¾æ¡ä»¶ã€‘\n"
            f"ãƒ»å‡ºåŠ›ã¯æ•´å½¢å¾Œã®æ–‡ç« ã®ã¿ï¼ˆå‰ç½®ããƒ»è§£èª¬ãƒ»æ³¨é‡ˆãªã—ï¼‰\n"
            f"ãƒ»å¿…ãšæ—¥æœ¬èªã®ã¿\n"
            f"ãƒ»å›ºæœ‰åè©ï¼ˆäººå/ç¤¾å/å•†å“å/åœ°å/ç•ªçµ„åãªã©ï¼‰ã‚’ä½¿ã‚ãªã„\n"
            f"ãƒ»ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã€å¿œå‹Ÿæ–¹æ³•ã€å‘ŠçŸ¥ã ã‘ã®æ–‡ç« ãªã©æœ¬ç­‹ã«ä¸è¦ãªè¦ç´ ã¯å…¥ã‚Œãªã„\n"
            f"ãƒ»æ”¹è¡Œãªã—ä¸€æ®µè½\n"
            f"ãƒ»æ–‡ç« ã‚’é€”ä¸­ã§åˆ‡ã‚‰ãšã€å¿…ãšå®Œçµã•ã›ã‚‹\n"
            f"ãƒ»æ–‡æœ«ã¯å¿…ãšã€Œã€‚ã€ã§çµ‚ãˆã‚‹\n"
            f"ãƒ»èª‡å¤§è¡¨ç¾ã‚„æ–­å®šã¯é¿ã‘ã€ä¸Šå“ã§èª­ã¿ã‚„ã™ã„è¡¨ç¾ã«ã™ã‚‹\n"
            f"ãƒ»åºƒå‘Šæ–‡ã‚‰ã—ãã€èª­è€…ã¸ã®å‘¼ã³ã‹ã‘ï¼ˆä¾‹ï¼šãœã²ã€ä»Šã“ãã€ç¢ºã‹ã‚ãŸã„ã€ãªã©ï¼‰ã‚„è¡Œå‹•ã‚’ä¿ƒã™ä¸€è¨€ã‚’å¿…ãšå…¥ã‚Œã‚‹\n"
            f"ãƒ»æ–‡å­—æ•°ã¯å¿…ãš {target_chars} æ–‡å­—ã¡ã‚‡ã†ã©\n\n"
            f"ã€å…ƒã®æ–‡ç« ï¼ˆç¾åœ¨{length}æ–‡å­—ï¼‰ã€‘\n{ad}\n\n"
            f"ã€æ•´å½¢å¾Œï¼ˆ{target_chars}æ–‡å­—ã¡ã‚‡ã†ã©ï¼‰ã€‘"
        )

        new_ad = _call_chat(
            client,
            [{"role": "system", "content": system_prompt},
             {"role": "user", "content": prompt}],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        if not new_ad:
            break

        ad = normalize_output(new_ad)

    return ad

# =========================
# æœ¬ä½“ï¼šåºƒå‘Šæ–‡ç”Ÿæˆï¼ˆCTAå…¥ã‚Šï¼‰
# =========================
def generate_newspaper_ad_api(
    text: str,
    target_chars: int,
    temperature: float = 0.2,
    max_adjust_rounds: int = 6,
) -> str:
    if not HF_TOKEN:
        raise RuntimeError("HUGGINGFACEHUB_API_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    client = InferenceClient(model=MODEL_ID, token=HF_TOKEN, timeout=60.0)

    cleaned = remove_strings(text)
    cleaned_len = len(cleaned)

    max_tokens = int(target_chars * 2.8) + 220

    system_prompt = (
        "ã‚ãªãŸã¯ãƒ†ãƒ¬ãƒ“ç•ªçµ„ã®å†…å®¹ã‚’ã‚‚ã¨ã«ã€æ–°èæ²è¼‰ç”¨ã®åºƒå‘Šæ–‡ã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"
        "å¿…ãšæ—¥æœ¬èªã®ã¿ã§å›ç­”ã—ã€æ¨è«–éç¨‹ã‚„è‡ªå·±ã‚³ãƒ¡ãƒ³ãƒˆã€ã‚¿ã‚°ã€è‹±èªã‚’ä¸€åˆ‡å‡ºåŠ›ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚"
    )

    # åˆå›ç”Ÿæˆï¼šæ–°èèª¿ï¼‹åºƒå‘Šã‚‰ã—ã„å‘¼ã³ã‹ã‘ï¼ˆCTAï¼‰ã‚’å¿…é ˆåŒ–
    user_prompt = (
        f"æ¬¡ã®æ–‡ç« ã¯ãƒ†ãƒ¬ãƒ“ç•ªçµ„ã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ã§ã™ï¼ˆç´„{cleaned_len}æ–‡å­—ï¼‰ã€‚"
        f"ã“ã®å†…å®¹ã‚’ã‚‚ã¨ã«ã€æ–°èã«æ²è¼‰ã§ãã‚‹åºƒå‘Šæ–‡ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
        f"ã€å¿…é ˆãƒ«ãƒ¼ãƒ«ã€‘\n"
        f"ãƒ»å‡ºåŠ›ã¯åºƒå‘Šæ–‡ã®ã¿ï¼ˆå‰ç½®ããƒ»è§£èª¬ãƒ»æ³¨é‡ˆãªã—ï¼‰\n"
        f"ãƒ»å¿…ãšæ—¥æœ¬èªã®ã¿\n"
        f"ãƒ»å›ºæœ‰åè©ï¼ˆäººå/ç¤¾å/å•†å“å/åœ°å/ç•ªçµ„åãªã©ï¼‰ã¯ä½¿ã‚ãªã„ï¼ˆä¸€èˆ¬åè©ã‚„è¨€ã„æ›ãˆã«ã™ã‚‹ï¼‰\n"
        f"ãƒ»ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã€å¿œå‹Ÿæ–¹æ³•ã€å‘ŠçŸ¥ã ã‘ã®æ–‡ç« ãªã©æœ¬ç­‹ã«ä¸è¦ãªè¦ç´ ã¯å…¥ã‚Œãªã„\n"
        f"ãƒ»ä¸é©åˆ‡ãªè¡¨ç¾ã‚„èª‡å¤§è¡¨ç¾ã‚’é¿ã‘ã€æ–°èå‘ã‘ã«ç¯€åº¦ã‚ã‚‹åºƒå‘Šæ–‡ã«ã™ã‚‹\n"
        f"ãƒ»èª­è€…ã«å‘ã‘ãŸå‘¼ã³ã‹ã‘ã‚„è¡Œå‹•ã‚’ä¿ƒã™ä¸€è¨€ï¼ˆä¾‹ï¼šãœã²ã€ç¢ºã‹ã‚ãŸã„ã€è¦‹é€ƒã›ãªã„ã€ãªã©ï¼‰ã‚’å¿…ãšå…¥ã‚Œã‚‹\n"
        f"ãƒ»æ”¹è¡Œã¯ä½¿ã‚ãšä¸€æ®µè½\n"
        f"ãƒ»æ–‡ç« ã‚’é€”ä¸­ã§åˆ‡ã‚‰ãšå¿…ãšå®Œçµã•ã›ã€æ–‡æœ«ã¯ã€Œã€‚ã€ã§çµ‚ãˆã‚‹\n"
        f"ãƒ»æ–‡å­—æ•°ã¯ len()ã§æ•°ãˆã¦ {target_chars} æ–‡å­—ã¡ã‚‡ã†ã©\n\n"
        f"ã€åŸç¨¿ã€‘\n{cleaned}\n\n"
        f"ã€æ–°èåºƒå‘Šæ–‡ï¼ˆ{target_chars}æ–‡å­—ã¡ã‚‡ã†ã©ï¼‰ã€‘"
    )

    ad = _call_chat(
        client,
        [{"role": "system", "content": system_prompt},
         {"role": "user", "content": user_prompt}],
        max_tokens=max_tokens,
        temperature=temperature,
    )
    if not ad:
        return "åºƒå‘Šæ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

    ad = normalize_output(ad)

    # èª¿æ•´ãƒ«ãƒ¼ãƒ—ï¼šé•·çŸ­ã®è£œæ­£ï¼ˆCTAã‚’ç¶­æŒï¼‰
    for _ in range(max_adjust_rounds):
        length = count_chars(ad)
        if length == target_chars and ad.endswith("ã€‚"):
            return ad

        if length > target_chars:
            diff = length - target_chars
            adjust_prompt = (
                f"æ¬¡ã®æ–°èåºƒå‘Šæ–‡ã¯ len() ã§ {length} æ–‡å­—ã§ã™ã€‚æŒ‡å®šã¯ {target_chars} æ–‡å­—ã¡ã‚‡ã†ã©ã§ã€{diff} æ–‡å­—è¶…ãˆã¦ã„ã¾ã™ã€‚\n"
                f"æ„å‘³ã‚’å¤‰ãˆãšã€å›ºæœ‰åè©ã‚’ä½¿ã‚ãšã€ä¸è¦ãªã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ç­‰ã‚’å…¥ã‚Œãšã€"
                f"åºƒå‘Šæ–‡ã‚‰ã—ã„å‘¼ã³ã‹ã‘ï¼ˆè¡Œå‹•ã‚’ä¿ƒã™ä¸€è¨€ï¼‰ã‚’æ®‹ã—ãŸã¾ã¾ã€"
                f"æ–‡ç« ã‚’é€”ä¸­ã§åˆ‡ã‚‰ãšã«å¿…ãšå®Œçµã•ã›ã€æ–‡æœ«ã€Œã€‚ã€ã§ã€"
                f"ã¡ã‚‡ã†ã© {target_chars} æ–‡å­—ã«çŸ­ãä¿®æ­£ã—ã¦ãã ã•ã„ã€‚\n"
                f"ã€å³å®ˆã€‘å‡ºåŠ›ã¯ä¿®æ­£æ–‡ã®ã¿ï¼æ”¹è¡Œãªã—ï¼å‰ç½®ããƒ»è§£èª¬ãƒ»è‹±èªãƒ»æ€è€ƒéç¨‹ã¯ç¦æ­¢\n\n"
                f"ã€å…ƒã®åºƒå‘Šæ–‡ã€‘\n{ad}\n\n"
                f"ã€ä¿®æ­£å¾Œï¼ˆ{target_chars}æ–‡å­—ã¡ã‚‡ã†ã©ï¼‰ã€‘"
            )
        else:
            diff = target_chars - length
            adjust_prompt = (
                f"æ¬¡ã®æ–°èåºƒå‘Šæ–‡ã¯ len() ã§ {length} æ–‡å­—ã§ã™ã€‚æŒ‡å®šã¯ {target_chars} æ–‡å­—ã¡ã‚‡ã†ã©ã§ã€{diff} æ–‡å­—è¶³ã‚Šã¾ã›ã‚“ã€‚\n"
                f"æ„å‘³ã‚’å¤‰ãˆãšã€å›ºæœ‰åè©ã‚’ä½¿ã‚ãšã€ä¸è¦ãªã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ç­‰ã‚’å…¥ã‚Œãšã€"
                f"åºƒå‘Šæ–‡ã‚‰ã—ã„å‘¼ã³ã‹ã‘ï¼ˆè¡Œå‹•ã‚’ä¿ƒã™ä¸€è¨€ï¼‰ã‚’å¿…ãšå«ã‚ã€"
                f"æ–‡ç« ã‚’é€”ä¸­ã§åˆ‡ã‚‰ãšã«å¿…ãšå®Œçµã•ã›ã€æ–‡æœ«ã€Œã€‚ã€ã§ã€"
                f"ã¡ã‚‡ã†ã© {target_chars} æ–‡å­—ã«ãªã‚‹ã‚ˆã†æœ€å°é™ã ã‘è£œã£ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚\n"
                f"ã€å³å®ˆã€‘å‡ºåŠ›ã¯ä¿®æ­£æ–‡ã®ã¿ï¼æ”¹è¡Œãªã—ï¼å‰ç½®ããƒ»è§£èª¬ãƒ»è‹±èªãƒ»æ€è€ƒéç¨‹ã¯ç¦æ­¢\n\n"
                f"ã€å…ƒã®åºƒå‘Šæ–‡ã€‘\n{ad}\n\n"
                f"ã€ä¿®æ­£å¾Œï¼ˆ{target_chars}æ–‡å­—ã¡ã‚‡ã†ã©ï¼‰ã€‘"
            )

        ad_new = _call_chat(
            client,
            [{"role": "system", "content": system_prompt},
             {"role": "user", "content": adjust_prompt}],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        if not ad_new:
            break

        ad = normalize_output(ad_new)

    # ä»•ä¸Šã’ï¼ˆCTAå¿…é ˆã§æ•´å½¢ï¼‰
    ad = finalize_with_llm(
        client=client,
        system_prompt=system_prompt,
        ad=ad,
        target_chars=target_chars,
        max_tokens=max_tokens,
        temperature=temperature,
        rounds=10,
    )
    ad = normalize_output(ad)

    # ã¾ã ã‚ºãƒ¬ã‚‹å ´åˆï¼šå¥èª­ç‚¹ã‚«ãƒƒãƒˆâ†’ä»•ä¸Šã’
    if count_chars(ad) != target_chars or not ad.endswith("ã€‚"):
        ad = smart_cut_to_sentence(ad, target_chars)
        ad = finalize_with_llm(
            client=client,
            system_prompt=system_prompt,
            ad=ad,
            target_chars=target_chars,
            max_tokens=max_tokens,
            temperature=temperature,
            rounds=10,
        )
        ad = normalize_output(ad)

    # æœ€çµ‚ä¿é™º
    if count_chars(ad) != target_chars:
        ad = smart_cut_to_sentence(ad, target_chars)

    if count_chars(ad) == target_chars and not ad.endswith("ã€‚") and target_chars >= 1:
        ad = ad[:-1] + "ã€‚"

    return ad

# =========================
# CLIï¼šç›®æ¨™æ–‡å­—æ•°å…¥åŠ›
# =========================
def ask_target_chars(default: int = 120, min_chars: int = 30, max_chars: int = 400) -> int:
    while True:
        raw = input(f"ğŸ“ ç›®æ¨™æ–‡å­—æ•°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ{min_chars}ã€œ{max_chars}ã€æœªå…¥åŠ›ãªã‚‰ {default}ï¼‰ï¼š").strip()
        if raw == "":
            return default
        if not raw.isdigit():
            print("âš ï¸ æ•°å­—ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            continue
        val = int(raw)
        if not (min_chars <= val <= max_chars):
            print(f"âš ï¸ ç¯„å›²å¤–ã§ã™ã€‚{min_chars}ã€œ{max_chars} ã®é–“ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            continue
        return val

# ==============================
# âœ… å…¥åŠ› & å®Ÿè¡Œï¼ˆCLIï¼‰
# ==============================
if __name__ == "__main__":
    if not HF_TOKEN:
        raise RuntimeError("HUGGINGFACEHUB_API_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    target_chars = ask_target_chars(default=120)

    print("\nğŸ“ åºƒå‘Šæ–‡ã«ã—ãŸã„åŸç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°è¡ŒOKï¼‰")
    print("   å…¥åŠ›çµ‚äº†ã¯ç©ºè¡Œï¼ˆEnterã®ã¿ï¼‰ã§ã™ã€‚\n")

    lines = []
    while True:
        line = input()
        if line.strip() == "":
            break
        lines.append(line)

    text = "\n".join(lines)

    print("\n--- æ–°èèª¿ åºƒå‘Šæ–‡ï¼ˆç”Ÿæˆçµæœï¼‰---\n")
    result = generate_newspaper_ad_api(
        text=text,
        target_chars=target_chars,
        temperature=0.2,
        max_adjust_rounds=6,
    )

    print(result)
    print(f"\næ–‡å­—æ•°ï¼š{len(result)}")
