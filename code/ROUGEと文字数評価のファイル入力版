# --- å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« ---
# æ—¥æœ¬èªã®åˆ†ã‹ã¡æ›¸ãã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ROUGEã‚¹ã‚³ã‚¢ã®è¨ˆç®—ã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
print("--- å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­ ---")
!pip install -q ipadic mecab-python3 rouge-score pandas openpyxl
print("--- ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº† ---")

import os
import glob
import pandas as pd
import math
import time
from collections import defaultdict
from google.colab import drive 
import MeCab
import ipadic
from rouge_score import rouge_scorer, scoring

# MeCab/ipadicã®åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯
MECAB_READY = False
try:
    # IPAdicã‚’ç”¨ã„ãŸMeCabã‚’ä½¿ç”¨ã—ã¦ã€å˜èªåˆ†å‰²ã‚’è¡Œã†ã‚¿ã‚¬ãƒ¼ã‚’åˆæœŸåŒ–
    tagger = MeCab.Tagger(f"-O wakati {ipadic.MECAB_ARGS}")
    MECAB_READY = True
    print("âœ… MeCab/ipadicã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚ROUGEã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¾ã™ã€‚")
except Exception as e:
    print(f"ğŸš¨ MeCab/ipadicã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ROUGEã‚¹ã‚³ã‚¢ã®è¨ˆç®—ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")


# --- 1. NumberScoreã®é–¢æ•°å®šç¾© (æ–‡å­—æ•°é©åˆåº¦ã®è©•ä¾¡) ---
def length_score(text, target):
    """è·é›¢ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚³ã‚¢: 1 - |len(text) - target| / target"""
    length = len(text)
    diff = abs(length - target)
    score = max(0, 1 - diff / target)
    return score

def evaluate_summary_length(text, target, tolerance=5):
    """è¨±å®¹ç¯„å›² Â± tolerance ã‚’æŒã¤å®Ÿç”¨çš„ãªã‚¹ã‚³ã‚¢"""
    length = len(text)
    diff = abs(length - target)

    if diff <= tolerance:
        return 1.0

    score = max(0, 1 - (diff - tolerance) / target)
    return score


# --- 2. ROUGEã®é–¢æ•°å®šç¾© (å†…å®¹ã®é¡ä¼¼åº¦è©•ä¾¡) ---
def convert_words_to_ids(predictions: list[str], references: list[str]) -> tuple[list[str], list[str]]:
    """å˜èªåˆ—ã‚’IDåˆ—ã«å¤‰æ›ã—ã€æ—¥æœ¬èªã¯MeCabã§åˆ†ã‹ã¡æ›¸ãã‚’è¡Œã†"""
    # å˜èªã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªIDã‚’å‰²ã‚Šå½“ã¦ã‚‹ãŸã‚ã®defaultdictã‚’ä½œæˆã™ã‚‹
    word2id = defaultdict(lambda: len(word2id))

    # å˜èªåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã‚’IDæ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹
    pred_ids = [
        " ".join([str(word2id[w]) for w in tagger.parse(p).strip().split()])
        for p in predictions
    ]
    ref_ids = [
        " ".join([str(word2id[w]) for w in tagger.parse(r).strip().split()])
        for r in references
    ]
    return pred_ids, ref_ids

def compute_rouge(predictions: list[str], references: list[str]) -> dict[str, scoring.Score]:
    """ROUGEã‚’ç®—å‡º (å…¨ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆå€¤)"""
    if not MECAB_READY:
        return {}
        
    rouge = rouge_scorer.RougeScorer(
        rouge_types=["rouge1", "rouge2", "rougeL"], use_stemmer=False
    )
    aggregator = scoring.BootstrapAggregator()
    
    pred_ids, ref_ids = convert_words_to_ids(predictions, references)
    
    for pred, ref in zip(pred_ids, ref_ids):
        if not pred.strip() or not ref.strip():
            continue
            
        aggregator.add_scores(rouge.score(ref, pred))
        
    scores = aggregator.aggregate()
    # v.mid ã¯ MidScore ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚Šã€ã“ã‚Œã« .fmeasure å±æ€§ãŒã‚ã‚‹
    return {k: v.mid for k, v in scores.items()}


# --- 3. CSVèª­ã¿è¾¼ã¿ã¨è©•ä¾¡ã®ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

def evaluate_summaries_from_csv(folder_path: str, csv_file_name: str, 
                                target_chars_column: str, summary_column: str, 
                                source_column: str):
    
    if not os.path.isdir(folder_path):
        print(f"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {folder_path}")
        return

    csv_path = os.path.join(folder_path, csv_file_name)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åãŒæœªæŒ‡å®šã®å ´åˆã€æœ€æ–°ã®è¦ç´„çµæœCSVã‚’æ¢ã™
    if not csv_file_name:
        csv_files = glob.glob(os.path.join(folder_path, "summary_Qwen3_*.csv"))
        if not csv_files:
            print("âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€å†…ã«è¦ç´„çµæœã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        csv_path = max(csv_files, key=os.path.getctime)
        print(f"ğŸ’¡ æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {os.path.basename(csv_path)} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    
    if not os.path.exists(csv_path):
        print(f"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        return

    print(f"\n--- CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {os.path.basename(csv_path)} ---")
    
    try:
        df = pd.read_csv(csv_path, encoding='utf-8-sig')
    except Exception as e:
        print(f"ğŸš¨ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # å¿…é ˆåˆ—ã®ç¢ºèª
    required_cols = [target_chars_column, summary_column, source_column]
    if not all(col in df.columns for col in required_cols):
        print("ğŸ›‘ ã‚¨ãƒ©ãƒ¼: CSVã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print(f"  å¿…é ˆåˆ—: {required_cols}")
        print(f"  å­˜åœ¨ã™ã‚‹åˆ—: {list(df.columns)}")
        return

    print(f"--- è©•ä¾¡è¨ˆç®—ã‚’é–‹å§‹ ({len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿) ---")

    # NumberScoreã®è¨ˆç®—
    df['NumberScore_simple'] = df.apply(
        lambda row: length_score(row[summary_column], row[target_chars_column]), axis=1
    )
    df['NumberScore_practical'] = df.apply(
        lambda row: evaluate_summary_length(row[summary_column], row[target_chars_column]), axis=1
    )
    print("âœ… NumberScoreã®è¨ˆç®—å®Œäº†ã€‚")


    # ROUGEã‚¹ã‚³ã‚¢ã®è¨ˆç®— (ä¿®æ­£æ¸ˆã¿)
    if MECAB_READY:
        print("\n--- ROUGEã‚¹ã‚³ã‚¢è¨ˆç®—ä¸­ (å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‚ç…§ã¨ã—ã¦ä½¿ç”¨) ---")
        
        try:
            predictions = df[summary_column].tolist()
            references = df[source_column].tolist() 
            
            rouge_scores = compute_rouge(predictions, references)
            
            if rouge_scores:
                # ğŸ› ï¸ ä¿®æ­£: MidScoreã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å±æ€§ã‚’ç›´æ¥å‚ç…§ã™ã‚‹ (.fmeasure)
                rouge1_f1 = rouge_scores['rouge1'].fmeasure
                rouge2_f1 = rouge_scores['rouge2'].fmeasure
                rougeL_f1 = rouge_scores['rougeL'].fmeasure

                # å…¨è¡Œã«é›†è¨ˆæ¸ˆã¿ã®F1ã‚¹ã‚³ã‚¢ã‚’é©ç”¨
                df['ROUGE-1_F1'] = rouge1_f1
                df['ROUGE-2_F1'] = rouge2_f1
                df['ROUGE-L_F1'] = rougeL_f1
                print("âœ… ROUGEã‚¹ã‚³ã‚¢è¨ˆç®—å®Œäº†ã€‚")
            
        except Exception as e:
            print(f"ğŸš¨ ROUGEã‚¹ã‚³ã‚¢è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ROUGEã‚¹ã‚³ã‚¢ãŒ0ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§è¨ˆç®—ã•ã‚Œã€è¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
    else:
        print("âš ï¸ ROUGEã‚¹ã‚³ã‚¢ã¯ã€MeCab/ipadicã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã®ãŸã‚è¨ˆç®—ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        
    
    # å¹³å‡å€¤ã®ç®—å‡ºã¨å‡ºåŠ›
    print("\n--- è©•ä¾¡çµæœã®å¹³å‡å€¤ ---")
    
    score_cols = ['NumberScore_simple', 'NumberScore_practical']
    if MECAB_READY and 'ROUGE-L_F1' in df.columns:
         score_cols.extend(['ROUGE-1_F1', 'ROUGE-2_F1', 'ROUGE-L_F1'])
         
    average_scores = df[score_cols].mean().to_frame(name='å¹³å‡ã‚¹ã‚³ã‚¢').round(4)
    print(average_scores.to_markdown())


    # è©•ä¾¡çµæœã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
    output_eval_path = csv_path.replace(".csv", "_Evaluated.csv")
    df.to_csv(output_eval_path, index=False, encoding='utf-8-sig')
    print(f"\n--- âœ… è©•ä¾¡çµæœã‚’CSVã«ä¿å­˜ã—ã¾ã—ãŸ: {os.path.basename(output_eval_path)} ---")
    
    # çµæœDataFrameã®è¡¨ç¤º
    print("\n--- è©•ä¾¡çµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å…ˆé ­5è¡Œ) ---")
    display_cols = ['ãƒ•ã‚¡ã‚¤ãƒ«å', 'è¦ç´„æ–‡å­—æ•°_å®Ÿéš›', 'NumberScore_practical']
    if 'ROUGE-L_F1' in df.columns:
        display_cols.extend(['ROUGE-1_F1', 'ROUGE-L_F1'])
    
    print(df[display_cols].head().to_markdown(floatfmt=".4f"))


# ==================================
# === å®Ÿè¡Œè¨­å®šã‚¨ãƒªã‚¢ (ã“ã“ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„) ===
# ==================================

print("\n--- ğŸ“‚ Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¾ã™ ---")
drive.mount('/content/drive')

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Ÿè¡Œçµæœã«åŸºã¥ãã€è¨­å®šã‚’å¾©å…ƒ
FOLDER_NAME = "tv" 
folder_path = f"/content/drive/MyDrive/{FOLDER_NAME}"
# ã‚¨ãƒ©ãƒ¼å ±å‘Šã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç›´æ¥æŒ‡å®š
CSV_FILE_NAME = "summary_Qwen3_20251211_151525.csv" 
SOURCE_COLUMN = "å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ˆé ­100æ–‡å­—ï¼‰" 

# ãƒ¡ã‚¤ãƒ³é–¢æ•°ã‚’å®Ÿè¡Œ
evaluate_summaries_from_csv(
    folder_path=folder_path, 
    csv_file_name=CSV_FILE_NAME,
    target_chars_column="è¦ç´„æ–‡å­—æ•°_å¸Œæœ›",
    summary_column="è¦ç´„çµæœ",
    source_column=SOURCE_COLUMN
)
