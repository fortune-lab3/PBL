!pip install -q "transformers>=4.51.0" accelerate bitsandbytes sentencepiece python-docx pandas

import os
import glob
import pandas as pd
from docx import Document
import torch
import time
import re
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from google.colab import drive # Driveãƒã‚¦ãƒ³ãƒˆã®ãŸã‚ã«è¿½åŠ 

# --- 1. Qwen3-8B ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æº–å‚™ (4bit é‡å­åŒ–) ---
print("--- ğŸ§  Qwen3-8B ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­ (4bité‡å­åŒ–) ---")
model_name = "Qwen/Qwen3-8B"

# Qwen3-8B ã¯ VRAM ã‚’å¤§é‡ã«æ¶ˆè²»ã™ã‚‹ãŸã‚ã€4bit é‡å­åŒ–ã¯å¿…é ˆ
if not torch.cuda.is_available():
    raise SystemExit("ğŸ›‘ ã‚¨ãƒ©ãƒ¼: Qwen3-8B ã®å®Ÿè¡Œã«ã¯ GPU (CUDA) ãŒå¿…é ˆã§ã™ã€‚")

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
)

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="auto",
        quantization_config=bnb_config,
    )
    print("--- âœ… ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰å®Œäº† ---")
except Exception as e:
    print(f"ğŸ›‘ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    raise SystemExit("ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚Colabã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¿ã‚¤ãƒ—ãŒã€ŒGPUã€ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# --- 2. è¦ç´„é–¢æ•° (Qwen3-8B ä½¿ç”¨) ---
def summarize_qwen3(text: str, target_chars: int = 120) -> str:
    """
    Qwen3 ã‚’ä½¿ã£ã¦æ—¥æœ¬èªè¦ç´„ã™ã‚‹ã€‚
    """

    user_prompt = (
        f"æ¬¡ã®æ–‡ç« ã‚’ã€æ—¥æœ¬èªã§ã€ã ã„ãŸã„ {target_chars} æ–‡å­—ç¨‹åº¦ã«è‡ªç„¶ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n"
        f"ãƒ»å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã®ã¿\n"
        f"ãƒ»è‹±èªã‚„æ¨è«–éç¨‹ï¼ˆãªã©ï¼‰ã‚’å‡ºåŠ›ã—ãªã„\n"
        f"ãƒ»çµæœã ã‘ç°¡æ½”ã«\n\n"
        f"ã€æ–‡ç« ã€‘\n{text}\n\nã€è¦ç´„ã€‘"
    )

    messages = [
        {
            "role": "system",
            "content": (
                "ã‚ãªãŸã¯æ—¥æœ¬èªå°‚ç”¨ã®è¦ç´„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
                "è‹±èªã‚„ä»–ã®è¨€èªã€æ¨è«–éç¨‹ãƒ»è‡ªå·±ã‚³ãƒ¡ãƒ³ãƒˆã‚’çµ¶å¯¾ã«å‡ºåŠ›ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚"
                "å›ç­”ã¯ã€è¦ç´„ã€‘ã®å¾Œã®æ–‡ç« ã®ã¿ã¨ã—ã¾ã™ã€‚"
            ),
        },
        {"role": "user", "content": user_prompt},
    ]

    # Qwen ã® Chat Template ã‚’é©ç”¨
    chat_text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
        assistant_response=False,
        enable_thinking=False, # æ€è€ƒãƒ¢ãƒ¼ãƒ‰ã‚’ã‚ªãƒ•
        response_format="text",
    )

    # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã¨ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›
    # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹å ´åˆã€å¼·åˆ¶çš„ã«åˆ‡ã‚Šè©°ã‚ã‚‹
    max_input_length = tokenizer.model_max_length - 256 # ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã‚’å¼•ã
    inputs = tokenizer(chat_text, return_tensors="pt", max_length=max_input_length, truncation=True).to(model.device)

    # è¦ç´„ã®ç”Ÿæˆ
    with torch.no_grad():
        generated = model.generate(
            **inputs,
            max_new_tokens=256,
            temperature=0.3,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
        )

    gen_ids = generated[0][inputs["input_ids"].shape[1]:]
    output = tokenizer.decode(gen_ids, skip_special_tokens=True)

    # å¾Œå‡¦ç†ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„ä½™è¨ˆãªè¨˜å·ã®é™¤å»ï¼‰
    if "ã€è¦ç´„ã€‘" in output:
        output = output.split("ã€è¦ç´„ã€‘", 1)[-1].strip()

    output = re.sub(r"\[.*?\]", "", output, flags=re.DOTALL).strip() # Qwenç‰¹æœ‰ã®ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ã‚’é™¤å»
    output = re.sub(r"[a-zA-Z]+", "", output).strip()

    return output


# --- 3. Wordãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–¢æ•° ---
def read_docx(file_path):
    """Wordãƒ•ã‚¡ã‚¤ãƒ« (.docx) ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°"""
    try:
        document = Document(file_path)
        # æ®µè½å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆã€‚æ”¹è¡Œã¯ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®ãæ›ãˆ
        full_text = "\n".join([p.text.strip() for p in document.paragraphs if p.text.strip()])
        return full_text
    except Exception as e:
        print(f"  ğŸš¨ Wordãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        return None

# --- 4. ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•° (ãƒ•ã‚©ãƒ«ãƒ€å†…ã® .docx ã‚’è¦ç´„ã— CSV ã«ä¿å­˜) ---
def summarize_folder_to_csv(folder_path: str, target_chars: int, output_csv: str):
    """ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®.docxãƒ•ã‚¡ã‚¤ãƒ«ã‚’Qwen3-8Bã§è¦ç´„ã—ã€çµæœã‚’CSVã«ä¿å­˜ã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°"""

    if not os.path.isdir(folder_path):
        print(f"ğŸ›‘ ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {folder_path}")
        return

    print(f"\n--- ãƒ•ã‚©ãƒ«ãƒ€å†…ã®.docxãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­: {folder_path} ---")

    file_list = glob.glob(os.path.join(folder_path, "*.docx"))

    if not file_list:
        print("ğŸ›‘ æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€å†…ã«.docxãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    results = []
    print(f"--- âœ… {len(file_list)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ (ãƒ¢ãƒ‡ãƒ«: Qwen3-8B) ---")

    for i, file_path in enumerate(file_list):
        start_time = time.time()
        file_name = os.path.basename(file_path)
        print(f"\n[{i+1}/{len(file_list)}] ğŸ“„ å‡¦ç†ä¸­: {file_name}")

        original_text = read_docx(file_path)

        if original_text and original_text.strip():
            try:
                # Qwen3-8B ã«ã‚ˆã‚‹è¦ç´„å®Ÿè¡Œ
                summary_text = summarize_qwen3(original_text, target_chars=target_chars)

                actual_length = len(summary_text)
                elapsed_time = time.time() - start_time
                print(f"   -> è¦ç´„å®Œäº† (æ–‡å­—æ•°: {actual_length}, å‡¦ç†æ™‚é–“: {elapsed_time:.2f}ç§’)")

                results.append({
                    "ãƒ•ã‚¡ã‚¤ãƒ«å": file_name,
                    "å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ˆé ­100æ–‡å­—ï¼‰": original_text[:100].replace('\n', ' ') + "...",
                    "è¦ç´„æ–‡å­—æ•°_å¸Œæœ›": target_chars,
                    "è¦ç´„æ–‡å­—æ•°_å®Ÿéš›": actual_length,
                    "è¦ç´„çµæœ": summary_text
                })
            except Exception as e:
                print(f"   ğŸš¨ è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                results.append({
                    "ãƒ•ã‚¡ã‚¤ãƒ«å": file_name,
                    "å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ˆé ­100æ–‡å­—ï¼‰": "å‡¦ç†ã‚¨ãƒ©ãƒ¼",
                    "è¦ç´„æ–‡å­—æ•°_å¸Œæœ›": target_chars,
                    "è¦ç´„æ–‡å­—æ•°_å®Ÿéš›": 0,
                    "è¦ç´„çµæœ": f"è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}"
                })
        else:
            print("   âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã‹ã€èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            results.append({
                "ãƒ•ã‚¡ã‚¤ãƒ«å": file_name,
                "å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ˆé ­100æ–‡å­—ï¼‰": "ãƒ†ã‚­ã‚¹ãƒˆãªã—/èª­ã¿è¾¼ã¿å¤±æ•—",
                "è¦ç´„æ–‡å­—æ•°_å¸Œæœ›": target_chars,
                "è¦ç´„æ–‡å­—æ•°_å®Ÿéš›": 0,
                "è¦ç´„çµæœ": "å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—"
            })

    # çµæœã‚’Pandas DataFrameã«ã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    if results:
        df = pd.DataFrame(results)
        df.to_csv(output_csv, index=False, encoding='utf-8-sig')
        print(f"\n--- âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã‚’CSVã«ä¿å­˜ã—ã¾ã—ãŸ: {output_csv} ---")
    else:
        print("\n--- å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã¯ä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ ---")

# ==================================
# === å®Ÿè¡Œéƒ¨åˆ† (Google Colab / ãƒ‘ã‚¹å›ºå®š) ===
# ==================================

print("\n--- ğŸ“‚ Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¾ã™ ---")
drive.mount('/content/drive')

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã‚¨ãƒªã‚¢ ---
# è¦ç´„å¯¾è±¡ã® .docx ãŒå…¥ã£ã¦ã„ã‚‹ Google Drive å†…ã®ãƒ•ã‚©ãƒ«ãƒ€åã‚’è¨­å®šã—ã¦ãã ã•ã„
FOLDER_NAME = "tv"
folder_path = f"/content/drive/MyDrive/{FOLDER_NAME}"
# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã‚¨ãƒªã‚¢çµ‚ã‚ã‚Š ---

print(f"\n--- ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚©ãƒ«ãƒ€: {folder_path} ---")

# ç›®æ¨™æ–‡å­—æ•°ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å…¥åŠ›ã—ã¦ã‚‚ã‚‰ã†
try:
    target = int(input("ã ã„ãŸã„ä½•æ–‡å­—ãã‚‰ã„ã§è¦ç´„ã—ã¦ã»ã—ã„ã§ã™ã‹ï¼Ÿï¼ˆæ¨å¥¨ï¼š100ï½250ï¼‰ï¼š"))
except ValueError:
    print("å…¥åŠ›ãŒä¸æ­£ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®120æ–‡å­—ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    target = 120

# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¨­å®š
timestamp = time.strftime('%Y%m%d_%H%M%S')
output_file = os.path.join(folder_path, f"summary_Qwen3_{timestamp}.csv")

# ãƒ¡ã‚¤ãƒ³é–¢æ•°ã‚’å®Ÿè¡Œ
summarize_folder_to_csv(folder_path, target_chars=target, output_csv=output_file)
