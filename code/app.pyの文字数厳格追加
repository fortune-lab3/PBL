#200å­—æŒ‡å®šã§5å›å®Ÿè¡Œã—ãŸã‚‰(194,178,195,198,170å­—)ã§ã—ãŸ
#APIã®å‘¼ã³å‡ºã—ã¯æœ€å¤§7å›ã«ãªã£ã¡ã‚ƒã„ã¾ã—ãŸ

import os, time, re, base64
import streamlit as st
from huggingface_hub import InferenceClient
from httpx import ConnectTimeout, ReadTimeout, HTTPError

# ------------------------------------------------
# Hugging Face è¨­å®š
# ------------------------------------------------
HF_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN", "")
MODEL_ID = "Qwen/Qwen3-4B-Instruct-2507"

# =========================
# âœ… APIå‘¼ã³å‡ºã—å›æ•°ã®ä¸Šé™ï¼ˆæœ€å¤§5å›ï¼‰
# =========================
MAX_API_CALLS = 5
_api_call_count = 0

# =========================
# å‰å‡¦ç†
# =========================
def remove_strings(text: str) -> str:
    pattern = re.compile(r'ã€.*?ã€‘|[ï¼²R][ãƒ¼-]\d+|\n|\t|\s+|â– |ï¼Š')
    return pattern.sub('', text or "")

def normalize_output(text: str) -> str:
    text = (text or "").strip()
    text = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL)
    text = re.sub(r"[a-zA-Z]+", "", text)
    return text.replace("\n", "").replace("\r", "").strip()

def count_chars(text: str) -> int:
    return len((text or "").replace("\n", "").replace("\r", ""))

# =========================
# æ–‡åˆ†å‰²
# =========================
def split_sentences(text: str) -> list[str]:
    text = normalize_output(text)
    parts = re.split(r"(ã€‚)", text)
    sentences = []
    for i in range(0, len(parts) - 1, 2):
        sentences.append(parts[i] + "ã€‚")
    return sentences

# =========================
# HF å¿œç­”æŠ½å‡º & å‘¼ã³å‡ºã—
# =========================
def _extract_message_text(choice) -> str:
    msg = getattr(choice, "message", None)
    if isinstance(msg, dict):
        return msg.get("content", "")
    return getattr(msg, "content", "")

def _call_chat(client, messages, max_tokens, temperature):
    """
    âœ… æœ€å¤§ MAX_API_CALLS å›ã¾ã§ã—ã‹ API ã‚’å‘¼ã°ãªã„
    â€»ãƒªãƒˆãƒ©ã‚¤æ™‚ã‚‚ã€Œå‘¼ã³å‡ºã—ã€ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã—ã¾ã™
    """
    global _api_call_count

    if _api_call_count >= MAX_API_CALLS:
        return ""

    for attempt in range(3):
        try:
            if _api_call_count >= MAX_API_CALLS:
                return ""

            _api_call_count += 1
            resp = client.chat.completions.create(
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
            )
            return _extract_message_text(resp.choices[0]).strip()

        except (ConnectTimeout, ReadTimeout):
            time.sleep(2 ** attempt)
        except HTTPError as e:
            if getattr(e.response, "status_code", 500) >= 500:
                time.sleep(2 ** attempt)
            else:
                raise
    return ""

# =========================
# å¾ŒåŠã ã‘å†èª¿æ•´ï¼ˆåˆ‡ã‚‰ãªã„ï¼‰
# =========================
def adjust_tail_with_llm(
    client,
    head_sentences: list[str],
    tail_sentence: str,
    target_chars: int,
    temperature: float,
) -> str:
    head = "".join(head_sentences)

    prompt = (
        f"æ¬¡ã®æ–°èåºƒå‘Šæ–‡ã®ã€å¾ŒåŠã€‘ã ã‘ã‚’ã€æ„å‘³ã‚’å¤‰ãˆãšã«è‡ªç„¶ã«æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\n"
        f"ã€æ¡ä»¶ã€‘\n"
        f"ãƒ»å‰åŠã¯å¤‰æ›´ã—ãªã„\n"
        f"ãƒ»å…¨ä½“ãŒã ã„ãŸã„ {target_chars} æ–‡å­—å‰å¾Œã«ãªã‚‹ã‚ˆã†èª¿æ•´\n"
        f"ãƒ»æ”¹è¡Œãªã—ä¸€æ®µè½\n"
        f"ãƒ»å›ºæœ‰åè©ã‚’ä½¿ã‚ãªã„\n"
        f"ãƒ»èª‡å¤§è¡¨ç¾ã‚’é¿ã‘ã‚‹\n"
        f"ãƒ»æ–‡æœ«ã¯å¿…ãšã€Œã€‚ã€ã§çµ‚ãˆã‚‹\n\n"
        f"ã€å‰åŠã€‘\n{head}\n\n"
        f"ã€å¾ŒåŠï¼ˆä¿®æ­£å¯¾è±¡ï¼‰ã€‘\n{tail_sentence}\n\n"
        f"ã€ä¿®æ­£å¾Œã®å¾ŒåŠã€‘"
    )

    new_tail = _call_chat(
        client,
        [{"role": "user", "content": prompt}],
        max_tokens=200,
        temperature=temperature,
    )

    # å‘¼ã¹ãªã‹ã£ãŸå ´åˆã¯å…ƒã®æœ«å°¾ã‚’ç¶­æŒ
    if not new_tail:
        return head + normalize_output(tail_sentence)

    return head + normalize_output(new_tail)

# ============================================================
# âœ… ã“ã“ã‹ã‚‰ã€Œæ–‡å­—æ•°å³æ ¼åŒ–ã€éƒ¨åˆ†ï¼ˆè¿½åŠ åæ˜ ï¼‰
# ============================================================

# æœ€çµ‚ä¿é™ºï¼šå¥èª­ç‚¹ã§è‡ªç„¶ã«åˆ‡ã‚‹
def smart_cut_to_sentence(text: str, target_chars: int, lookback: int = 40) -> str:
    text = normalize_output(text)
    if len(text) <= target_chars:
        return text

    head = text[:target_chars]
    puncts = {"ã€‚", "ï¼", "ï¼Ÿ"}
    start = max(0, target_chars - lookback)

    cut_pos = -1
    for i in range(target_chars - 1, start - 1, -1):
        if head[i] in puncts:
            cut_pos = i + 1
            break

    if cut_pos != -1:
        return head[:cut_pos]

    if target_chars >= 1:
        head = head[:-1] + "ã€‚"
    return head

# ä»•ä¸Šã’ï¼šå®Œçµãƒ»æ–‡æœ«ã€Œã€‚ã€ãƒ»ã¡ã‚‡ã†ã©Næ–‡å­—ï¼ˆå³æ ¼ï¼‰
def finalize_with_llm(
    client: InferenceClient,
    system_prompt: str,
    ad: str,
    target_chars: int,
    max_tokens: int,
    temperature: float,
    rounds: int = 8,
) -> str:
    ad = normalize_output(ad)

    for _ in range(rounds):
        length = count_chars(ad)
        if length == target_chars and ad.endswith("ã€‚"):
            return ad

        prompt = (
            f"æ¬¡ã®æ–‡ç« ã‚’ã€æ„å‘³ã‚’å¤‰ãˆãšã«æ–°èå‘ã‘ã®ç¯€åº¦ã‚ã‚‹åºƒå‘Šæ–‡ã¨ã—ã¦æ•´å½¢ã—ã¦ãã ã•ã„ã€‚\n"
            f"len()ã§æ•°ãˆã¦ã€Œ{target_chars}æ–‡å­—ã¡ã‚‡ã†ã©ã€ã«å¿…ãšåˆã‚ã›ã¾ã™ã€‚\n"
            f"ã€çµ¶å¯¾æ¡ä»¶ã€‘\n"
            f"ãƒ»å‡ºåŠ›ã¯æ•´å½¢å¾Œã®æ–‡ç« ã®ã¿ï¼ˆå‰ç½®ããƒ»è§£èª¬ãƒ»æ³¨é‡ˆãªã—ï¼‰\n"
            f"ãƒ»å¿…ãšæ—¥æœ¬èªã®ã¿\n"
            f"ãƒ»å›ºæœ‰åè©ï¼ˆäººå/ç¤¾å/å•†å“å/åœ°å/ç•ªçµ„åãªã©ï¼‰ã‚’ä½¿ã‚ãªã„\n"
            f"ãƒ»æ”¹è¡Œãªã—ä¸€æ®µè½\n"
            f"ãƒ»æ–‡ç« ã‚’é€”ä¸­ã§åˆ‡ã‚‰ãšã€å¿…ãšå®Œçµã•ã›ã‚‹\n"
            f"ãƒ»æ–‡æœ«ã¯å¿…ãšã€Œã€‚ã€ã§çµ‚ãˆã‚‹\n"
            f"ãƒ»èª‡å¤§è¡¨ç¾ã‚„æ–­å®šã¯é¿ã‘ã€ä¸Šå“ã§èª­ã¿ã‚„ã™ã„è¡¨ç¾ã«ã™ã‚‹\n"
            f"ãƒ»åºƒå‘Šæ–‡ã‚‰ã—ãã€èª­è€…ã¸ã®å‘¼ã³ã‹ã‘ã‚„è¡Œå‹•ã‚’ä¿ƒã™ä¸€è¨€ã‚’å¿…ãšå…¥ã‚Œã‚‹\n"
            f"ãƒ»æ–‡å­—æ•°ã¯å¿…ãš {target_chars} æ–‡å­—ã¡ã‚‡ã†ã©\n\n"
            f"ã€å…ƒã®æ–‡ç« ï¼ˆç¾åœ¨{length}æ–‡å­—ï¼‰ã€‘\n{ad}\n\n"
            f"ã€æ•´å½¢å¾Œï¼ˆ{target_chars}æ–‡å­—ã¡ã‚‡ã†ã©ï¼‰ã€‘"
        )

        new_ad = _call_chat(
            client,
            [{"role": "system", "content": system_prompt},
             {"role": "user", "content": prompt}],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        if not new_ad:
            break

        ad = normalize_output(new_ad)

    return ad

# ============================================================
# åºƒå‘Šæ–‡ç”Ÿæˆï¼ˆç²¾åº¦å„ªå…ˆï¼‰ + âœ… æ–‡å­—æ•°å³æ ¼åŒ–ï¼ˆå³æ ¼åŒ–ã¯æœ€å¤§3å›ï¼‰
# ============================================================
def generate_newspaper_ad_api(text: str, target_chars: int, temperature: float = 0.2) -> str:
    global _api_call_count
    _api_call_count = 0  # âœ… ç”Ÿæˆã”ã¨ã«ãƒªã‚»ãƒƒãƒˆ

    if not HF_TOKEN:
        raise RuntimeError("HUGGINGFACEHUB_API_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    client = InferenceClient(model=MODEL_ID, token=HF_TOKEN, timeout=60.0)

    cleaned = remove_strings(text)
    max_tokens = int(target_chars * 3)
    #ã“ã“ã«è¿½åŠ 
    long_target = target_chars + 25

    system_prompt = (
        "ã‚ãªãŸã¯ãƒ†ãƒ¬ãƒ“ç•ªçµ„ã®å†…å®¹ã‚’ã‚‚ã¨ã«ã€æ–°èæ²è¼‰ç”¨ã®åºƒå‘Šæ–‡ã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"
        "å¿…ãšæ—¥æœ¬èªã®ã¿ã§å›ç­”ã—ã€æ¨è«–éç¨‹ã‚„è‡ªå·±ã‚³ãƒ¡ãƒ³ãƒˆã€ã‚¿ã‚°ã€è‹±èªã‚’ä¸€åˆ‡å‡ºåŠ›ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚"
    )

    # â‘  è‡ªç„¶ã•æœ€å„ªå…ˆã§ç”Ÿæˆï¼ˆå…ƒã®ã¾ã¾ï¼‰
    ad = _call_chat(
        client,
        [{"role": "user", "content": (
            f"æ¬¡ã®åŸç¨¿å†…å®¹ã‚’ã‚‚ã¨ã«ã€æ–°èã«æ²è¼‰ã§ãã‚‹åºƒå‘Šæ–‡ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n"
            f"ãƒ»æ—¥æœ¬èªã®ã¿\n"
            f"ãƒ»å›ºæœ‰åè©ã‚’ä½¿ã‚ãªã„\n"
            f"ãƒ»æ”¹è¡Œãªã—ä¸€æ®µè½\n"
            f"ãƒ»æ–‡æœ«ã¯å¿…ãšã€Œã€‚ã€\n"
            f"ãƒ»æ–‡å­—æ•°ã¯ãŠã‚ˆã {target_chars} æ–‡å­—å‰å¾Œ\n"
            f"ãƒ»ç„¡ç†ãªæ–‡å­—æ•°åˆã‚ã›ã¯ã—ãªã„\n\n"
            f"ã€åŸç¨¿ã€‘\n{cleaned}\n\nã€åºƒå‘Šæ–‡ã€‘"
        )}],
        max_tokens=max_tokens,
        temperature=temperature,
    )

    if not ad:
        return ""

    ad = normalize_output(ad)
    sentences = split_sentences(ad)

    # â‘¡ é•·ã™ãã‚‹å ´åˆã®ã¿æœ€å¾Œã®1æ–‡ã‚’å†èª¿æ•´ï¼ˆå…ƒã®ã¾ã¾ï¼‰
    if len(sentences) >= 2 and len(ad) > target_chars + 10:
        ad = adjust_tail_with_llm(
            client,
            head_sentences=sentences[:-1],
            tail_sentence=sentences[-1],
            target_chars=target_chars,
            temperature=temperature,
        )

    # âœ… â‘¢ len()ã§ target_chars æ–‡å­—ã¡ã‚‡ã†ã©ã«å¯„ã›ã‚‹ï¼ˆå³æ ¼åŒ–ã¯æœ€å¤§3å›ï¼‰
    ad = normalize_output(ad)

    max_tokens_strict = int(target_chars * 2.8) + 220

    # â”€â”€ å³æ ¼åŒ–ï¼šAPIæœ€å¤§5å›ã®é…åˆ† â”€â”€
    # èª¿æ•´ãƒ«ãƒ¼ãƒ—ï¼šæœ€å¤§4å›ï¼ˆ=4å›ï¼‰
    max_adjust_rounds = 4 # 2 -> 4

    for _ in range(max_adjust_rounds):
        length = count_chars(ad)
        if length == target_chars and ad.endswith("ã€‚"):
            return ad

        if length > target_chars:
            diff = length - target_chars
            adjust_prompt = (
                f"æ¬¡ã®æ–°èåºƒå‘Šæ–‡ã¯ len() ã§ {length} æ–‡å­—ã§ã™ã€‚æŒ‡å®šã¯ {target_chars} æ–‡å­—ã¡ã‚‡ã†ã©ã§ã€{diff} æ–‡å­—è¶…ãˆã¦ã„ã¾ã™ã€‚\n"
                f"æ„å‘³ã‚’å¤‰ãˆãšã€å›ºæœ‰åè©ã‚’ä½¿ã‚ãšã€åºƒå‘Šæ–‡ã‚‰ã—ã„å‘¼ã³ã‹ã‘ã‚’æ®‹ã—ãŸã¾ã¾ã€"
                f"æ–‡ç« ã‚’é€”ä¸­ã§åˆ‡ã‚‰ãšã«å¿…ãšå®Œçµã•ã›ã€æ–‡æœ«ã€Œã€‚ã€ã§ã€"
                f"ã¡ã‚‡ã†ã© {target_chars} æ–‡å­—ã«çŸ­ãä¿®æ­£ã—ã¦ãã ã•ã„ã€‚\n"
                f"ã€å³å®ˆã€‘å‡ºåŠ›ã¯ä¿®æ­£æ–‡ã®ã¿ï¼æ”¹è¡Œãªã—ï¼å‰ç½®ããƒ»è§£èª¬ãƒ»è‹±èªãƒ»æ€è€ƒéç¨‹ã¯ç¦æ­¢\n\n"
                f"ã€å…ƒã®åºƒå‘Šæ–‡ã€‘\n{ad}\n\n"
                f"ã€ä¿®æ­£å¾Œï¼ˆ{target_chars}æ–‡å­—ã¡ã‚‡ã†ã©ï¼‰ã€‘"
            )
        else:
            diff = target_chars - length
            adjust_prompt = (
                f"æ¬¡ã®æ–°èåºƒå‘Šæ–‡ã¯ len() ã§ {length} æ–‡å­—ã§ã™ã€‚æŒ‡å®šã¯ {target_chars} æ–‡å­—ã¡ã‚‡ã†ã©ã§ã€{diff} æ–‡å­—è¶³ã‚Šã¾ã›ã‚“ã€‚\n"
                f"æ„å‘³ã‚’å¤‰ãˆãšã€å›ºæœ‰åè©ã‚’ä½¿ã‚ãšã€åºƒå‘Šæ–‡ã‚‰ã—ã„å‘¼ã³ã‹ã‘ã‚’å¿…ãšå«ã‚ã€"
                f"æ–‡ç« ã‚’é€”ä¸­ã§åˆ‡ã‚‰ãšã«å¿…ãšå®Œçµã•ã›ã€æ–‡æœ«ã€Œã€‚ã€ã§ã€"
                f"ã¡ã‚‡ã†ã© {target_chars} æ–‡å­—ã«ãªã‚‹ã‚ˆã†æœ€å°é™ã ã‘è£œã£ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚\n"
                f"ã€å³å®ˆã€‘å‡ºåŠ›ã¯ä¿®æ­£æ–‡ã®ã¿ï¼æ”¹è¡Œãªã—ï¼å‰ç½®ããƒ»è§£èª¬ãƒ»è‹±èªãƒ»æ€è€ƒéç¨‹ã¯ç¦æ­¢\n\n"
                f"ã€å…ƒã®åºƒå‘Šæ–‡ã€‘\n{ad}\n\n"
                f"ã€ä¿®æ­£å¾Œï¼ˆ{target_chars}æ–‡å­—ã¡ã‚‡ã†ã©ï¼‰ã€‘"
            )

        ad_new = _call_chat(
            client,
            [{"role": "system", "content": system_prompt},
             {"role": "user", "content": adjust_prompt}],
            max_tokens=max_tokens_strict,
            temperature=temperature,
        )
        if not ad_new:
            break
        ad = normalize_output(ad_new)

    # finalizeï¼šæœ€å¤§1å›ï¼ˆ=1å›ï¼‰ â†’ å³æ ¼åŒ–åˆè¨ˆ æœ€å¤§3å›
    ad = finalize_with_llm(
        client=client,
        system_prompt=system_prompt,
        ad=ad,
        target_chars=target_chars,
        max_tokens=max_tokens_strict,
        temperature=temperature,
        rounds=1,
    )
    ad = normalize_output(ad)

    # âœ… APIãªã—æœ€çµ‚ä¿é™ºï¼ˆã‚ºãƒ¬ã¦ãŸã‚‰å¥èª­ç‚¹ã§èª¿æ•´ï¼‰
    if count_chars(ad) != target_chars or not ad.endswith("ã€‚"):
        ad = smart_cut_to_sentence(ad, target_chars)

    if count_chars(ad) == target_chars and not ad.endswith("ã€‚") and target_chars >= 1:
        ad = ad[:-1] + "ã€‚"

    return ad

# =========================
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯
# =========================
def create_download_link(content: str, filename: str):
    b64 = base64.b64encode(content.encode()).decode()
    return f'<a href="data:file/txt;base64,{b64}" download="{filename}">ğŸ“¥ åºƒå‘Šæ–‡ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'

# =========================
# Streamlit UI
# =========================
def main():
    st.title("è¦ç´„")

    text = st.text_area("åºƒå‘Šæ–‡ã«ã—ãŸã„åŸç¨¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=260)

    target_chars = st.number_input(
        "æ–‡å­—æ•°",
        min_value=30,
        max_value=500,
        value=200,
        step=1
    )

    if st.button("åºƒå‘Šæ–‡ã‚’ç”Ÿæˆ"):
        if not text.strip():
            st.warning("åŸç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        with st.spinner("åºƒå‘Šæ–‡ã‚’ç”Ÿæˆä¸­..."):
            try:
                ad = generate_newspaper_ad_api(text, target_chars)

                st.text_area("ç”Ÿæˆã•ã‚ŒãŸåºƒå‘Šæ–‡", ad, height=200)
                st.markdown(f"æ–‡å­—æ•°ï¼š{len(ad)} æ–‡å­—")
                st.markdown(create_download_link(ad, "newspaper_ad.txt"), unsafe_allow_html=True)

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# =========================
# å®Ÿè¡Œ
# =========================
if __name__ == "__main__":
    main()
